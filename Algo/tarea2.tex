\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{algorithm2e}
\usepackage{float}
%% Sets page size and margins
\usepackage[a4paper,top=2.5cm,bottom=2.5cm,left=2cm,right=2cm]{geometry}


%% Title
\title{
		\vspace{-0.7in}
		\usefont{OT1}{bch}{b}{n}
		\begin{minipage}{3cm}
        \vspace{-0.5in}
    	\begin{center}
    		\includegraphics[height=3.2cm]{../logo_unam.png}
    	\end{center}
    \end{minipage}\hfill
    \begin{minipage}{10.7cm}

    	\begin{center}
\normalfont \normalsize \textsc{UNIVERSIDAD NACIONAL AUTÓNOMA DE MÉXICO \\ FACULTAD DE CIENCIAS \\ Análisis de Algoritmos } \\
		\huge Tarea 2
    	\end{center}

    \end{minipage}\hfill
    \begin{minipage}{3.2cm}
    \vspace{-0.5in}
    	\begin{center}
    		\includegraphics[height=3.2cm]{../logo_fc.png}
    	\end{center}
    \end{minipage}

\author{Escobar Gonzalez Isaac Giovani \hspace{1cm} 321336400\\
        Garduño Escobar Kevin Jonathan \hspace{0.5cm} 321070629\\
        Zaldivar Alanis Rodrigo \hspace{2.75cm} 424029605 }
\date{}
}

\begin{document}

\maketitle

\section*{Ejercicio 1}
Para los siguientes ejercicios, da el análisis de complejidad en tiempo y espacio, así como la demostración de correctitud. Ilustra la ejecución de los algoritmos con algunos ejemplares.
\begin{itemize}
    \item[1.A] Diseña un algoritmo para multiplicar dos números dados en el sistema romano.\\
    Por ejemplo, \textit{XIX} por \textit{XXXIV} es \textit{DCXLVI}.\\\\
    No es válido hacer un cambio al sistema arábigo.\\\\
    \textbf{Algoritmo:} Debido a la longitud del algoritmo, se decidió separarlo en diferentes algoritmos, algunos invocan otros algoritmos.\\

    \begin{algorithm}[H]
    \footnotesize
    \SetAlgorithmName{Algoritmo}{Romanos}{Multiplicación}
    \caption{separar(s)}
    \KwIn{String s con número romano}
    \KwOut{Arreglo de enteros de 7 posiciones}
    \SetAlgoLined
    \Begin{
        posiciones $\gets$ nuevo arreglo de 7 enteros inicializados en 0 \\
        finM, finD, finC, finL, finX, finV $\gets$ false \\

        \For{$i \gets 0$ \KwTo $s.length() - 1$}{
            \uIf{$s[i] =$ 'M'}{
                \eIf{finM}{
                    posiciones[1] $\gets$ posiciones[1] + 1 \\
                    posiciones[2] $\gets$ posiciones[2] + 3 \\
                }{
                    posiciones[0] $\gets$ posiciones[0] + 1 \\
                }
            }
            \uElseIf{$s[i] =$ 'D'}{
                \eIf{finD}{
                    posiciones[2] $\gets$ posiciones[2] + 3 \\
                }{
                    finM $\gets$ true \\
                    posiciones[1] $\gets$ posiciones[1] + 1 \\
                }
            }
            \uElseIf{$s[i] =$ 'C'}{
                \eIf{finC}{
                    posiciones[3] $\gets$ posiciones[3] + 1 \\
                    posiciones[4] $\gets$ posiciones[4] + 3 \\
                }{
                    finM $\gets$ true \\
                    finD $\gets$ true \\
                    posiciones[2] $\gets$ posiciones[2] + 1 \\
                }
            }
            \uElseIf{$s[i] =$ 'L'}{
                \eIf{finL}{
                    posiciones[4] $\gets$ posiciones[4] + 3 \\
                }{
                    finC $\gets$ true \\
                    posiciones[3] $\gets$ posiciones[3] + 1 \\
                }
            }
            \uElseIf{$s[i] =$ 'X'}{
                \eIf{finX}{
                    posiciones[5] $\gets$ posiciones[5] + 1 \\
                    posiciones[6] $\gets$ posiciones[6] + 3 \\
                }{
                    finC $\gets$ true \\
                    finL $\gets$ true \\
                    posiciones[4] $\gets$ posiciones[4] + 1 \\
                }
            }
            \uElseIf{$s[i] =$ 'V'}{
                \eIf{finV}{
                    posiciones[6] $\gets$ posiciones[6] + 3 \\
                }{
                    finX $\gets$ true \\
                    posiciones[5] $\gets$ posiciones[5] + 1 \\
                }
            }
            \uElseIf{$s[i] =$ 'I'}{
                finX $\gets$ true \\
                finV $\gets$ true \\
                posiciones[6] $\gets$ posiciones[6] + 1 \\
            }
        }
        \Return{posiciones}
    }
    \end{algorithm}
    \textbf{Complejidad:}
    \begin{itemize}
        \item Tiempo: Se declara y crea un arreglo de longitud 7, luego se declaran e inicializan 6 variables con false. Todo esto es $O(1)$.
        Luego, el ciclo for se ejecuta el mismo número de veces que
        la longitud de la cadena. En el cuerpo del for, no hay ningún ciclo presente. Solo hay condicionales, incrementos y asignaciones. Por lo cuál, el cuerpo del for tiene complejidad $O(1)$. Como la complejidad de un for es la complejidad de su cuerpo por el número de iteraciones de este, tenemos que su complejidad total es $O(n)$ si tomamos n como la longitud del número romano. Después de ejecutar el for, se hace un retorno que tiene complejidad $O(1)$. Por lo que la complejidad del algoritmo es $O(n)$ en tiempo.
        \item Espacio: Se declara y crea un arreglo de longitud 7, luego se declaran e inicializan 6 variables con false. Como la reserva del espacio en memoria en este caso no depende de la longitud del número romano, su complejidad es $O(1)$.
        En el ciclo, se crea la variable i (solo una vez en toda la ejecución del algoritmo). En el cuerpo del for no se reserva memoria, todas las operaciones son condicionales, sumas, accesos a memoria y asignaciones. Por lo que todo el for tiene complejidad $O(1)$. El retorno también tiene complejidad $O(1)$, por lo que todo el algoritmo tiene complejidad $O(1)$ en espacio.
    \end{itemize}
    \textbf{Correctitud:} Se crea un arreglo de longitud siete para almacenar los valores en romano de: M, D, C, L, X, V y I.
    Luego, las variables fin nos dicen si ya se leyó un símbolo con valor menor que el que llevan en su nombre, nos indican que la cadena de ese símbolo '\textit{ha llegado a su fin}' por lo que si aparece un símbolo de nuevo, se trata de \textit{notación sustractiva}.

    Proponemos la invariante: Antes de la i-ésima iteración, el producto punto del arreglo posiciones con valores = [1000,500,100,50,10,5,1] representa el valor parcial acumulado del s en la porción $s[0:i - 1]$.

    \textbf{Inicialización:} Antes de la primera iteración, todos los valores de posiciones son cero, por lo que el producto punto es cero. A pesar de que en los números romanos el cero no tiene una representación, podemos interpretar la usencia de símbolos como el cero.

    \textbf{Mantenimiento:} Supongamos que después de la k-ésima iteración, se cumplió la invariante.
    Ejecutamos el algoritmo:\\
    Procedemos a contemplar dos casos.\\
    Al leer un símbolo, la variable fin correspondiente a este símbolo es false (exceptuando I):
    En este caso, se incrementa en uno la posición del arreglo correspondiente al símbolo. En la posición 0 para M, 1 para D, 2 para C, 3 para L, 4 para X, 5 para V y 6 para I.
    Además de que si se leyó I, se asignan $finX$ y $finV$ como verdadero, si fue X, $finC$ y $finL$ son verdaderas; si fue C, $finD$ y $finM$ son verdaderas.
    En este caso, se sigue cumpliendo la invariante, ya que el producto punto del arreglo después de esta iteración $k + 1$ es el de la iteración k + (1000, 500, 100, 50, 10, 5 o 1) dependiendo si se leyó M, D, C, L, X, V o I respectivamente.\\
    En el caso en el que la variable fin correspondiente al símbolo leído es falsa, esto quiere decir que se presenta un caso de notación sustractiva.
    Si se leyó 'M' (caso CM):\\
    posiciones[1]++ (D → + 1 * 500)\\
    posiciones[2] += 3 (CCC → + 3 * 100)\\
    Total: +800, que sumado al 100 anterior (como finM es verdadera, la iteración anterior se leyó 'C' por lo que ya estaba incrementado en uno)da 900\\\\
    Si se leyó 'D' (caso CD):\\
    posiciones[2] += 3 (CCC → + 3 * 100 = +300)\\
    Total: +300, que sumado al 100 anterior (de la 'C' previa) da 400.\\\\
    Si se leyó 'C' (caso XC):\\
    posiciones[3]++ (L → + 1 * 50 = +50)\\
    posiciones[4] += 3 (XXX → + 3 * 10 = +30)\\
    Total: +80, que sumado al 10 anterior (de la 'X' previa) da 90.\\\\
    Si se leyó 'L' (caso XL):\\
    posiciones[4] += 3 (XXX → + 3 * 10 = +30)\\
    Total: +30, que sumado al 10 anterior (de la 'X' previa) da 40.\\\\
    Si se leyó 'X' (caso IX):\\
    posiciones[5]++ (V → + 1 * 5 = +5)\\
    posiciones[6] += 3 (III → + 3 * 1 = +3)\\
    Total: +8, que sumado al 1 anterior (de la 'I' previa) da 9.\\\\
    Si se leyó 'V' (caso IV):\\
    posiciones[6] += 3 (III → + 3 * 1 = +3)\\
    Total: +3, que sumado al 1 anterior (de la 'I' previa) da 4.\\\\
    Los anteriores casos cubren todos los casos de notación sustractiva romana, por lo que se cumple la invariante después de la iteración k + 1.
    \textbf{Terminación:} El ciclo termina debido a que se ejecuta mientras i sea menor que la longitud de la cadena e y se incrementea en uno en cada iteración.
    Como se vio en la parte de mantenimiento, después de n-ésima iteración, el producto punto del arreglo con los valores representa el valor correctamente de la cadena s[0:n - 1]. Es decir, de toda la cadena. Por lo que el algoritmo es correcto.

    \begin{algorithm}[H]
    \SetAlgorithmName{Algoritmo}{Romanos}{Multiplicación}
    \caption{multiplicar(a, b)}
    \KwIn{Dos arreglos de enteros a y b de 7 posiciones}
    \KwOut{Arreglo de enteros de 7 posiciones}
    \SetAlgoLined
    \Begin{
        c $\gets$ nuevo arreglo de 7 enteros inicializados en 0 \\
        valores $\gets$ [1000, 500, 100, 50, 10, 5, 1] \\

        \For{$i \gets 6$ \KwDownto $0$}{
            \For{$j \gets 6$ \KwDownto $0$}{
                \If{$b[i] \neq 0$}{
                    $c[j] \gets c[j] + a[j] \times b[i] \times valores[i]$ \\
                }
            }
        }
        \Return{c}
    }
    \end{algorithm}
    \textbf{Complejidad:}
    \begin{itemize}
        \item Tiempo: Se declara un nuevo arreglo c de tamaño 7 y un arreglo valores que se inicializan. Estas operaciones son $O(1)$. Luego se tienen dos bucles for anidados. El bucle interno se ejecuta 49 (O(49) = O(1)) veces y en su cuerpo se ejecuta una condicional, una asignación, una suma y 2 multiplicaciones y accesos a memoria.
        Todo esto es $O(1)$. El bucle externo también se ejecuta 7 veces y su cuerpo tiene complejidad $O(1)$. Al final, se devuelve el arreglo c, esto es $O(1)$. Por lo que el algoritmo tiene complejidad en tiempo de $O(1)$.
        \item Espacio: Tiempo: Se declara un nuevo arreglo c de tamaño 7 y un arreglo valores que se inicializan. Estas operaciones son $O(1)$. Son las únicas operaciones en las que se reservan espacios en memoria. Por lo que el algoritmo es $O(1)$ en espacio.
    \end{itemize}

    \textbf{Correctitud:} Como tenemos dos ciclos anidados, tendremos que hacer dos análisis por invariante:
    \begin{enumerate}
        \item Ciclo interno:
        Proponemos la invariante: Antes de cada iteración del ciclo interno, para un índice fijo $i$ del ciclo externo, cada posición de $c$ que ya se procesó ($k > j$) contiene la cantidad de símbolos de $a[k]$ multiplicada por la cantidad de símbolos de $b[i]$ y sumada a lo que ya estaba acumulado de iteraciones anteriores del ciclo externo. Las posiciones $k \le j$ aún no han sido actualizadas para este índice $i$.

        \textbf{Inicialización:} Antes de la primera iteración del ciclo interno, no hay posiciones procesadas, y la invariante se cumple.\\
        \textbf{Mantenimiento:} Si la invariante se cumple al inicio de la iteración $j$, tras actualizar $c[j]$, la posición $j$ se suma a las procesadas y la invariante sigue siendo cierta.\\
        \textbf{Terminación:} Al finalizar el ciclo interno ($j=-1$), todas las posiciones se han actualizado con la contribución de $b[i]$, es decir, cada posición $c[k]$ contiene correctamente la cantidad de símbolos de $a[k]$ multiplicada por $b[i]$ y sumada a lo acumulado.

        \item Ciclo externo:
        Proponemos como invariante: Antes de cada iteración del ciclo externo, cada posición $k$ de $c$ contiene la suma de todas las multiplicaciones de los símbolos de $a[k]$ por los símbolos de $b[m]$ ya procesados ($m > i$).

        \textbf{Inicialización:} Antes de la primera iteración del ciclo externo ($i=6$), $c[k]=0$ para todo $k$, la invariante se cumple.\\
        \textbf{Mantenimiento:} Tras ejecutar el ciclo interno para $i$, se agrega la contribución de $b[i]$, y la invariante se cumple para el siguiente $i-1$.\\
        \textbf{Terminación:} Cuando $i=-1$ (fin del ciclo externo), todas las posiciones se han procesado, es decir, cada posición $c[k]$ contiene la multiplicación completa de los símbolos correspondientes de $a[k]$ y $b$, garantizando que el número romano resultante será correcto.
    \end{enumerate}

    \begin{algorithm}[H]
    \caption{ajustar(c)}
    \SetAlgorithmName{Algoritmo}{Romanos}{Multiplicación}
    \KwIn{Arreglo de enteros a de 7 posiciones}
    \KwOut{Arreglo de enteros ajustado}
    \SetAlgoLined
    \Begin{
        c[5] $\gets$ c[5] + $\lfloor$c[6] / 5$\rfloor$ \\
        c[6] $\gets$ c[6] mod 5 \\

        c[4] $\gets$ c[4] + $\lfloor$c[5] / 2$\rfloor$ \\
        c[5] $\gets$ c[5] mod 2 \\

        c[3] $\gets$ c[3] + $\lfloor$c[4] / 5$\rfloor$ \\
        c[4] $\gets$ c[4] mod 5 \\

        c[2] $\gets$ c[2] + $\lfloor$c[3] / 2$\rfloor$ \\
        c[3] $\gets$ c[3] mod 2 \\

        c[1] $\gets$ c[1] + $\lfloor$c[2] / 5$\rfloor$ \\
        c[2] $\gets$ c[2] mod 5 \\

        c[0] $\gets$ c[0] + $\lfloor$c[1] / 2$\rfloor$ \\
        c[1] $\gets$ c[1] mod 2 \\

        \Return{c}
    }
    \end{algorithm}

        \textbf{Complejidad:}
        \begin{itemize}
            \item Tiempo: Como en este algoritmo no hay ningún ciclo involucrado, ni método ni llamadas recursivas. Si no, solamente asignaciones, accesos a memoria, divisiones, sumas y módulos, su complejidad en tiempo es O(1).
            \item Espacio: En este caso, no se reserva ningún espacio de memoria adicional, por lo que su complejidad es O(1).
        \end{itemize}
        \textbf{Correctitud:}
        El algoritmo normaliza un arreglo de 7 posiciones que representa un número romano en notación aditiva, asegurando que cumple con las reglas de la numeración romana estándar.

\textbf{Precondición:} El arreglo de entrada $a$ contiene conteos de símbolos romanos en el orden: \\
$[M, D, C, L, X, V, I]$

\textbf{Postcondición:} El arreglo resultante cumple:
\begin{itemize}
    \item $0 \leq a[6] \leq 4$ (máximo 4 I's)
    \item $0 \leq a[5] \leq 1$ (máximo 1 V)
    \item $0 \leq a[4] \leq 4$ (máximo 4 X's)
    \item $0 \leq a[3] \leq 1$ (máximo 1 L)
    \item $0 \leq a[2] \leq 4$ (máximo 4 C's)
    \item $0 \leq a[1] \leq 1$ (máximo 1 D)
    \item $a[0] \geq 0$
\end{itemize}

\textbf{Demostración de correctitud:}

    El algoritmo procesa los símbolos de menor a mayor valor (I → V → X → L → C → D → M), aplicando las conversiones:

    \begin{enumerate}
        \item \textbf{Nivel I-V:} Convierte cada 5 I's en 1 V
            \[
            a[5] += \lfloor a[6] / 5 \rfloor, \quad a[6] = a[6] \mod 5
            \]

        \item \textbf{Nivel V-X:} Convierte cada 2 V's en 1 X
            \[
            a[4] += \lfloor a[5] / 2 \rfloor, \quad a[5] = a[5] \mod 2
            \]

        \item \textbf{Nivel X-L:} Convierte cada 5 X's en 1 L
            \[
            a[3] += \lfloor a[4] / 5 \rfloor, \quad a[4] = a[4] \mod 5
            \]

        \item \textbf{Nivel L-C:} Convierte cada 2 L's en 1 C
            \[
            a[2] += \lfloor a[3] / 2 \rfloor, \quad a[3] = a[3] \mod 2
            \]

        \item \textbf{Nivel C-D:} Convierte cada 5 C's en 1 D
            \[
            a[1] += \lfloor a[2] / 5 \rfloor, \quad a[2] = a[2] \mod 5
            \]

        \item \textbf{Nivel D-M:} Convierte cada 2 D's en 1 M
            \[
            a[0] += \lfloor a[1] / 2 \rfloor, \quad a[1] = a[1] \mod 2
            \]
    \end{enumerate}
    El resultado final cumple todas las reglas de la numeración romana y representa el mismo valor numérico que la entrada.

\begin{algorithm}[H]
\caption{parse(c)}
\SetAlgorithmName{Algoritmo}{Romanos}{imprimir}

\KwIn{Arreglo de enteros c de 7 posiciones}
\KwOut{String con número romano}
\SetAlgoLined
\Begin{
    sb $\gets$ nuevo StringBuilder \\
    sim $\gets$ ['M', 'D', 'C', 'L', 'X', 'V', 'I'] \\

    \For{$i \gets 0$ \KwTo $6$}{
        \uIf{$i = 1$ \textbf{y} $c[1] = 1$ \textbf{y} $c[2] = 4$}{
            sb.append("CM") \\
            c[1] $\gets$ 0 \\
            c[2] $\gets$ 0 \\
        }
        \uIf{$i = 2$ \textbf{y} $c[2] = 4$}{
            sb.append("CD") \\
            c[2] $\gets$ 0 \\
        }
        \uIf{$i = 3$ \textbf{y} $c[3] = 1$ \textbf{y} $c[4] = 4$}{
            sb.append("XC") \\
            c[3] $\gets$ 0 \\
            c[4] $\gets$ 0 \\
        }
        \uIf{$i = 4$ \textbf{y} $c[4] = 4$}{
            sb.append("XL") \\
            c[4] $\gets$ 0 \\
        }
        \uIf{$i = 5$ \textbf{y} $c[5] = 1$ \textbf{y} $c[6] = 4$}{
            sb.append("IX") \\
            c[5] $\gets$ 0 \\
            c[6] $\gets$ 0 \\
        }
        \uIf{$i = 6$ \textbf{y} $c[6] = 4$}{
            sb.append("IV") \\
            c[6] $\gets$ 0 \\
        }

        \For{$j \gets 0$ \KwTo $c[i] - 1$}{
            sb.append(sim[i]) \\
        }
    }
    \Return{sb.toString()}
}
\end{algorithm}

    \textbf{Complejidad:}
    \begin{itemize}
        \item Tiempo: El algoritmo declara e inicializa dos variables nuevas al inicio. Después  entra en un ciclo que se ejecuta siete veces siempre. Luego, entra máximo solo un if por ejecución en el que máximo se ejecutan tres operaciones básicas. $O(1)$. Luego entra en un ciclo for interno que se ejecuta máximo tres veces debido a la normalización y en este se ejecuta solo una operación simple; por lo que el for interno tiene una complejidad O(1). Como todo el cuerpo del for externo tiene complejidad constante y este se ejecuta un número fijo de veces (7), su complejidad es constante O(1). El retorno es una operación constante, por lo que todo el algoritmo tiene complejidad O(1).
        \item \textbf{Espacio:} Como la complejidad en espacio se ve acotada por la complejidad en tiempo, esta es constante O(1).
    \end{itemize}
    \textbf{Correctitud:} En este algoritmo igualmente tendremos que
    utilizar dos invariantes para cada ciclo.\\
    \begin{enumerate}
        \item Interno:\\
        Proponemos la invariante: Antes de la k-ésima iteración, se han agregado k - 1 símbolos más correspondientes al valor de i (por este ciclo).
        \textbf{Inicialización:} Antes de entrar a la primera iteración no se han agregado símbolos correspondientes a este ciclo, por lo que tenemos k - 1 = 1 - 1 = 0 símbolos agregados.\\
        \textbf{Mantenimiento:}
        Supongamos que después de la l-ésima iteración, se mantuvo la invariante, l símbolos agregados. Al entrar a la l+1, se agrega el símbolo correspondiente a la misma i de nuevo. Por lo que tenemos en total l+1 símbolos antes de la iteración l+2. Por lo que la invariante se mantiene.\\
        \textbf{Terminación:} Como el arreglo c viene ajustado, este se ejecuta a lo más 3 veces. Por lo que siempre termina. Así, este ciclo agrega la cantidad de símbolos indicados por c[i].

        \item Externo:
        Proponemos la invariante: Antes de la $(i+1)$-ésima iteración, se habrá representado correctamente el valor original en números romanos utilizando los símbolos en el subarreglo $c[0:i-1]$ que nos permitan hacerlo.
        \textbf{Inicialización:} Antes de que se ejecute el ciclo, no se habrá representado ningún valor lo que es correspondiente al valor acumulado en el arreglo vacío.\\
        \textbf{Mantenimiento:} Supongamos que después de la iteración donde $i = k$, y antes de cuando $i = k + 1$; se mantuvo la invariante.
        Separemos esto en dos casos:
        \begin{enumerate}
            \item El número que representa i en sim[i] es ((M, C, X o I) y c[i] < 4) o (es (D, L o V) y c[i] < 2).\\
            En este caso, la numeración romana permite agregar directamente la cantidad de símbolos correspondientes a $i$
            por lo que se ejecuta el for interno y se agregan la cantidad de símbolos indicados por $i$. Por lo que después de cuando $i = k + 1$ y antes de cuando $i = k + 2$, se representó correctamente la parte del valor original que los símbolos en $c[0: k + 1]$ nos permiten.
            \item El número que representa i en sim[i] es
            C, X o I y $c[i] = 4$.\\
            En este caso, como no hay una representación consecutiva de símbolos para este valor, se asigna cero en $c[i]$ para que no se ejecute el for interno y después agregamos la cadena correspondiente que equivale a cuatro veces el símbolo. Ya sea, CD, XL o IV.
            O el número que se representa es D, L o V y c[i] == 1 y c[i + 1] == 4. Como no se pueden agregar 4 símbolos consecutivos, esto quiere decir que se debe utilizar notación sustractiva. Por lo que asignamos cero a $c[i]$ y a $c[i + 1]$. Agregamos la cadena correspondiente. Ya sea CM, XC o IX.\\
            No se entra en el ciclo interno.
            Por lo cuál después de la iteración se representó adecuadamente la parte del valor original que los símbolos en $c[0,k + 1]$ nos permiten.\\
            \textbf{Terminación:} Como el for externo se ejecuta 7 veces, termina. Y como nuestra invariante nos indica: Se representó adecuadamente la parte del valor que los símbolos en $[0:6]$ (inclusivo) nos permite representar. O sea, pudimos representar de manera correcta todo el valor porque ya se utilizaron potencialmente todos los símbolos.
        \end{enumerate}

        \end{enumerate}
            \begin{algorithm}[H]
        \caption{operar(s1, s2)}
        \SetAlgorithmName{Algoritmo}{Romanos}{operar}
        \KwIn{Dos strings s1 y s2 con números romanos}
        \SetAlgoLined
        \Begin{
            a $\gets$ separar(s1) \\
            b $\gets$ separar(s2) \\
            c $\gets$ multiplicar(a, b) \\
            c $\gets$ ajustar(c) \\
            imprimir(parse(c)) \\
        }
        \end{algorithm}
        \textbf{Complejidad:} En este algoritmo se hacen dos usos del algoritmo separar, uno de multiplicar, uno de ajusta y se imprime. Como Separar tiene complejidad O(n), este algoritmo también lo tiene.
        En espacio, como todos los algoritmos tienen complejidad constante, este también es O(1).

        \textbf{Correctitud:} Como los algoritmos separar reciben una entrada de números romanos bien formados y da como salida un arreglo que representa el mismo valor, multiplicar los recibe y da como salida un arreglo cuyo valor representa la multiplicación de los dos números. Luego, ajusta da su representación aditiva y el método imprimir, como vimos da la representación correcta de la multiplicación. Por lo que el algoritmo es correcto.

        \textbf{Ejecución:} Probaremos el algoritmo con las entradas 'IV' y 'IX'.\\
    Separar\\
    \begin{verbatim}
    Entrada: "IX"
    i=0: 'I' → finX=true, finV=true, posiciones[6]=1
    i=1: 'X' → finX=true → posiciones[5]++, posiciones[6]+=3
    Resultado: [0,0,0,0,0,1,4] (Valor: 5 + 4 = 9)
    \end{verbatim}

    Separar\\
    \begin{verbatim}
    Entrada: "IV"
    i=0: 'I' → finX=true, finV=true, posiciones[6]=1
    i=1: 'V' → finV=true → posiciones[6]+=3
    Resultado: [0,0,0,0,0,0,4] (Valor: 4 = 4)
    \end{verbatim}

    Multiplicar\\
    \begin{verbatim}
    valores = [1000,500,100,50,10,5,1]
    Para i=6 (I): b[6]=4 ≠0
    j=6: c[6] += a[6]b[6]valores[6] = 4*4*1 = 16
    j=5: c[5] += a[5]b[6]valores[6] = 1*4*1 = 4
    ... (para otros j)
    Para i=5 (V): b[5]=0 → skip
    ... (para otros i)
    Resultado: [0,0,0,0,0,4,16]
    \end{verbatim}

    Ajustar\\
    \begin{verbatim}
    a[6]=16 → residuo=1, a[5]+=3, a[6]=1
    a[5]=7 → a[4]+=3, a[5]=1
    a[4]=3 → a[3]+=0, a[4]=3
    a[3]=0 → a[2]+=0, a[3]=0
    a[2]=0 → a[1]+=0, a[2]=0
    a[1]=0 → a[0]+=0, a[1]=0
    Resultado: [0,0,0,0,3,1,1]
    \end{verbatim}

    Parse\\
    \begin{verbatim}
    i=4: X=3 → "XXX"
    i=5: V=1 → "V"
    i=6: I=1 → "I"
    Resultado final: "XXXVI" (36) //Resultado correcto
    Verificación: 9 × 4 = 36
    \end{verbatim}
    A excepción de la ejecución del primero algoritmo, la salida de los algoritmos,
    fue la entrada del siguiente.

    Ahora probaremos con II y III (más compacto):\\
    \begin{verbatim}
    separar("III") → [0,0,0,0,0,0,3]
    separar("II") → [0,0,0,0,0,0,2]
    multiplicar:
        i=6: c[6] += 3*2*1 = 6
        Resultado: [0,0,0,0,0,0,6]
    ajusta([0,0,0,0,0,0,6]):
        a[6]=6 → residuo=1, a[5]+=1, a[6]=1
        a[5]=1 → a[4]+=0, a[5]=1
        Resultado: [0,0,0,0,0,1,1]
    parse([0,0,0,0,0,1,1]) = "VI" (6)
    \end{verbatim}


    \item[1.B] Dado un arreglo $A$ de $n$ bits y un entero $k > 0$, describe un algoritmo para encontrar el subarreglo más pequeño de $A$ que contiene $k$ unos.

    \begin{algorithm}[H]
    \caption{Subarreglo mínimo con $k$ unos}
    \KwIn{Arreglo de bits $A$ de longitud $n$, entero $k > 0$}
    \KwOut{Índices $(i,j)$ del subarreglo más pequeño con exactamente $k$ unos}
    \SetAlgoLined
    \Begin{
        min\_len $\gets n + 1$ \\
        min\_indices $\gets (-1,-1)$ \\
        unos $\gets 0$\\
        \For{$i \gets 0$ \KwTo $n-1$}{
            unos $\gets 0$ \\
            \For{$j \gets i$ \KwTo $n-1$}{
                \If{$A[j] = 1$}{
                    unos++\\
                }
                \If{unos = k \textbf{and} (j - i + 1) $<$ min\_len}{
                    min\_len $\gets j - i + 1$ \\
                    min\_indices $\gets (i,j)$ \\
                    \textbf{break} \\
                }
            }
        }
        \Return{min\_indices}
    }
    \end{algorithm}

    \textbf{Complejidad:}
    Tiempo: Se declaran tres variables y se inicializan, esto es complejidad O(1).
    Luego se tiene un ciclo for que va desde cero hasta $n - 1$ con incrementos de uno en uno.\\
    En su cuerpo:
    Asignación de variable, O(1).\\
    Inicia otro ciclo for de i hasta n - 1 de uno  en uno.
    Dentro del for, solamente hay operaciones de comparación asignación y operaciones aritméticas, por lo que la complejidad del cuerpo del for anidado es O(1). La complejidad del for anidado por sí solo es O(n).\\La complejidad del for externo: Su cuerpo tiene complejidad O(n) y se ejecuta O(n) veces, por lo que su complejidad es $O(n^2)$.

    Espacio: Solo se reserva espacio de memoria en las tres primeras líneas. Que solo se ejecutan una vez dentro del algoritmo. Por lo que tiene complejidad $O(1)$ en espacio.

    \textbf{Correctitud:} Como se tienen dos ciclos for anidados, hacemos primero la invariante del ciclo interno.

    Interno:\\
    Proponemos como invariante: Con $i$ fija, antes de la iteración donde j = l, tenemos que se han contado el número de unos en el subarreglo $[i:l - 1]$ y si hubo algún subarreglo que empezara en $i$ y terminara en $j'$ con $i \leq j' \leq j$ tal que $unos = k$ y $j' - i + 1 < min_len$, entonces $min\_len$ ahora contiene ese valor.
    \textbf{Inicialización:} Antes de que se ejecute la primera iteración ($j = i$), $unos$ vale cero y ningún subarreglo $A[1:j']$ ha sido guardado en min\_len porque el arreglo es vacío, por lo que se cumple la invariante.\\
    \textbf{Mantenimiento:} Supongamos que se cumple la invariante antes de cuando $j = l$, es decir. Se tienen el número de unos presentes en $A[i:l-1]$ y en caso de haber un subarreglo $A[i:j']$ tal que $unos = k$ y fuera de menor tamaño que $min\_len$, entonces está almacenado.
    Si $A[l] == 1$, entonces incrementa $unos$, en caso contrario, no.
    Si se incrementó unos, $unos = k$ y $l - i + 1 < min\_len$, entonces $min\_indices = (i, l)$, en caso contrario, no sucede nada. Así que al final de la
    l-ésima iteración, la invariante se mantiene.
    \textbf{Finalización:} El ciclo termina debido a que se ejecuta siempre que $j < n$ y j incrementa de uno en uno.
    Además, por la invariante, se tiene que si existió un subarreglo $A[i, j']$, $i \leq j' \leq n - 1$ con $k$ unos y su longitud menor a $min\_len$, entonces, este está guardado en min\_len y sus índices en $min\_indices$.

    Externo:\\
    Proponemos como invariante: Antes de cuando i = l, $min\_indices$ contiene los índices del subarreglo $A[i':n - 1]$, $0 \leq i' \leq i$ con menor longitud que tiene $k$ unos (si es que existe).\\
    \textbf{Inicialización:} Antes de comenzar el ciclo, min\_indices contiene (-1,-1), los cuáles son índices inválidos, por lo cuál pueden representar al arreglo vacío. Se cumple la invariante por vacuidad.\\
    \textbf{Mantenimiento:} Supongamos que mantuvo la invariante antes de la que i = l. Si ejecutamos el ciclo, tenemos que por la invariante del ciclo interno, si un subarreglo A[l:j'] con $l \leq j' \leq n - 1$ menor a min\_len con k unos, sus índices están en min\_len, de lo contrario, no sucedió nada en esa iteración.
    Si aunamos esto a la invariante de la iteración anterior, tenemos que si el arreglo se encuentra entre $A[i':j']$, $0 \leq i' \leq i$ y $i \leq j' \leq n - 1$, en caso contrario, min\_indices = (-1, -1). Por lo tanto, invariante se mantiene.\\
    \textbf{Terminación:} El ciclo termina porque va desde cero hasta $n-1$ con un incremento por iteración.
    De acuerdo al mantenimiento de la invariante, si existe un subarreglo que cumpla la propiedad en el rango $A[i':j']$, $0 \leq i' \leq j \leq n - 1$, sus índices están en min\_indices. Es decir, si existe algún arreglo con k unos en A, los índices del mínimo están en min\_indices. Por lo que el algoritmo es correcto.

    \textbf{Ejecución}: Ejecutamos primero el algoritmo con [0, 1, 1, 0, 1, 0, 1] y k = 3.
    \begin{verbatim}
        INICIO:
      min_len = 8
      min_indices = (-1, -1)

    i = 0:
      unos = 0
      j = 0: A[0]=0 → unos=0
      j = 1: A[1]=1 → unos=1
      j = 2: A[2]=1 → unos=2
      j = 3: A[3]=0 → unos=2
      j = 4: A[4]=1 → unos=3 → longitud=5 → min_len=5, min_indices=(0,4)

    i = 1:
      unos = 0
      j = 1: A[1]=1 → unos=1
      j = 2: A[2]=1 → unos=2
      j = 3: A[3]=0 → unos=2
      j = 4: A[4]=1 → unos=3 → longitud=4 → min_len=4, min_indices=(1,4)

    i = 2:
      unos = 0
      j = 2: A[2]=1 → unos=1
      j = 3: A[3]=0 → unos=1
      j = 4: A[4]=1 → unos=2
      j = 5: A[5]=0 → unos=2
      j = 6: A[6]=1 → unos=3 → longitud=5 (no actualiza, 5 > 4)

    i = 3:
      unos = 0
      j = 3: A[3]=0 → unos=0
      j = 4: A[4]=1 → unos=1
      j = 5: A[5]=0 → unos=1
      j = 6: A[6]=1 → unos=2

    i = 4:
      unos = 0
      j = 4: A[4]=1 → unos=1
      j = 5: A[5]=0 → unos=1
      j = 6: A[6]=1 → unos=2

    i = 5:
      unos = 0
      j = 5: A[5]=0 → unos=0
      j = 6: A[6]=1 → unos=1

    i = 6:
      unos = 0
      j = 6: A[6]=1 → unos=1

    RESULTADO: (1, 4)
    Subarreglo: A[1:4] = [1, 1, 0, 1] (longitud 4, 3 unos)
    \end{verbatim}

    Ahora hacemos la ejecución con [1,1,1,1] y k = 2
    \begin{verbatim}
        INICIO:
          min_len = 5
          min_indices = (-1, -1)

        i = 0:
          unos = 0
          j = 0: A[0]=1 → unos=1
          j = 1: A[1]=1 → unos=2 → longitud=2 → min_len=2, min_indices=(0,1)

        i = 1:
          unos = 0
          j = 1: A[1]=1 → unos=1
          j = 2: A[2]=1 → unos=2 → longitud=2 → min_len=2

        i = 2:
          unos = 0
          j = 2: A[2]=1 → unos=1
          j = 3: A[3]=1 → unos=2 → longitud=2 → min_len=2

        i = 3:
          unos = 0
          j = 3: A[3]=1 → unos=1

        RESULTADO: (0, 1)
        Subarreglo: A[0:1] = [1,1] (longitud 2, 2 unos)
    \end{verbatim}

    \item[1.C] Dado un arreglo $A$ que contiene $n - 1$ enteros  únicos en el rango $[0, n - 1]$; existe un número que no se encuentra en el arreglo. Diseña un algoritmo de complejidad en tiempo $O(n)$ y espacio $O(1)$ para encontrar ese número.

    \begin{algorithm}[H]
    \caption{faltante}
    \KwIn{Arreglo de enteros $arr$ de longitud $n-1$}
    \KwOut{Número faltante en el arreglo}
    suma $\gets 0$ \\
    \For{$i \gets 0$ \KwTo $n-2$}{
        suma $\gets$ suma $+$ arr[i] \\
    }
    \Return{$\frac{n(n - 1)}{2}$ $-$ suma}
    \end{algorithm}

    \textbf{Complejidad:}\\
    Tiempo: En la primera línea del algoritmo, se declara la valiable suma y se le asigna cero. O(1).\\
    En el for, este se ejecuta n + 1 veces y en su cuerpo hace
    1 suma, 1 acceso a memoria y una asignación.
    Como el for depende de n y su cuerpo es constante, su complejidad es O(n).\\
    En el retorno se hacen dos multiplicaciones, una división y dos restas. Toda la línea es O(n).\\
    Como la complejidad más grande en sus operaciones fue O(n), la complejidad del algoritmo es O(n) en tiempo.

    \textbf{Espacio}: En espacio, solo se reseva el espacio en memoria para la suma que al ser un valor numérico, es un valor fijo. Por lo que su complejidad es O(1).

    \textbf{Correctitud:}
    Para la correctitud, propononemos una invariante para el ciclo for.
    Esta es: Antes de la iteración donde i = k, se ha calculado la suma de los elementos del arreglo $[0:k-1]$.\\
    \textbf{Inicialización:} Antes de la iteración donde i = 0, (antes de la primera iteración), el arreglo sobre el que se ha calculado la suma es el vacío, por lo que la suma debería ser cero. Esto se cumple.\\
    \textbf{Mantenimiento:} Supongamos que se mantuvo la invariante antes de la iteración donde i = k, es decir, después de la iteración en la que i = k + 1. Al ejecutar el ciclo, se le suma la posición arr[i] a \textit{suma}, por lo que al terminar la k-ésima iteración y antes de empezar la k + 1, se calculó la suma del subarreglo $[0, k]$. Por lo que se cumple la invariante.\\
    \textbf{Finalización:} Como el ciclo se ejecuta mientras i sea menor a n - 1 e i se incrementa al finalizar cada ciclo, este termina. Además de que antes de la iteración donde $i = n - 1$ se calculó la suma de $arr[0:n - 2]$. Por lo que se ha calculado la suma de todo el subarreglo.
    Y la invariante es correcta.\\
    Después, regresamos el valor que da restar la suma de Gauss hasta $n - 1$ menos suma. Esto da el valor esperado porque suma tiene valores entre 0 hasta n - 1. Lo cuál podemos expresar en una ecuación, donde e es el número que falta. \[suma + e = \frac{n(n - 1)}{2}\] Si despejamos, obtenemos el valor de e que se ve reflejado en el retorno.

    \textbf{Ejecución:}\\
    \begin{verbatim}
        ENTRADA: arr = [0, 1, 2, 3, 5, 6] , n = 7
        Rango completo: [0, 1, 2, 3, 4, 5, 6]
        Número faltante: 4
        EJECUCIÓN:
          suma = 0
          i=0: suma = 0 + 0 = 0
          i=1: suma = 0 + 1 = 1
          i=2: suma = 1 + 2 = 3
          i=3: suma = 3 + 3 = 6
          i=4: suma = 6 + 5 = 11
          i=5: suma = 11 + 6 = 17
          suma_total_esperada = 7*6/2 = 21
          resultado = 21 - 17 = 4
    \end{verbatim}
\end{itemize}


% P-2
\section*{Ejercicio 2}
La búsqueda binaria trabaja dividiendo el problema a la mitad.
\begin{itemize}
    \item[2.A] Propón un algoritmo iterativo para una búsqueda ternaria, que divida el problema en tres partes; debe hacer a los más dos comparaciones y trabajar con un problema de tamaño $n/3$. Realiza el análisis de complejidad de tiempo y espacio, y la demostración de correctitud.\\
    \begin{algorithm}[H]
    \caption{Búsqueda ternaria}
    \KwIn{Arreglo ordenado $A$ de longitud $n$, $target$}
    \KwOut{Índice del elemento si se encuentra, $-1$ en otro caso}
    \SetAlgoLined
    \Begin{
        $l \gets 0$ \\
        $r \gets n - 1$ \\
        \While{$l \leq r$}{
            $micha1 \gets l + \frac{(r-l)}{3}$ \\
            $micha2 \gets r - \frac{(r-l)}{3}$ \\

            \If{$A[micha1] = target$}{
                \Return{$micha1$}
            }
            \If{$A[micha2] = target$}{
                \Return{$micha2$}
            }

            \If{$target < A[micha1]$}{
                $r \gets micha1 - 1$ \\
            }
            \ElseIf{$target > A[micha2]$}{
                $l \gets micha2 + 1$ \\
            }
            \Else{
                $l \gets micha1 + 1$ \\
                $r \gets micha2 - 1$ \\
            }
        }
        \Return{$-1$}
    }
    \end{algorithm}
    \textbf{Complejidad:}
    \begin{itemize}
        \item Tiempo: Se hacen dos declaraciones y dos asignaciones en las dos primeras líneas. Esto es O(1).
        Después entra a un ciclo.
        En su cuerpo se calcula los dos pivotes que dividen el subarreglo en 3, se hacen comparaciones, condicionales, accesos a memoria, sumas, restas y asignaciones. Todo el cuerpo $\in O(1)$.\\
        Ahora bien, en el peor de los casos, el elemento no se encuentra dentro del arreglo. En cada iteración, el subarreglo entre l y r, se divide en tres partes casi iguales. Y tamaño del arreglo sobre el que quedan los pivotes se reduce por lo menos en 1 en el mejor caso, por lo que eventualmente sucede que l > r. Como el arreglo se divide entre tres por cada iteración, tenemos que tiene una complejidad de $O(log(n))$.\\
        \item Espacio: En este algoritmo solo se declaran las variables l y r al inicio antes de entrar al algoritmo, por lo que tiene complejidad en espacio constante $O(1)$.
    \end{itemize}

    \textbf{Correctitud:} Para probar la correctitud del algoritmo, es necesario hacer un análisis por invariante del ciclo porque es el que hace la búsqueda.\\
    Proponemos como invariante: Si el elemento target se encuentra en el arreglo, este siempre estará entre l y r.
    Inicialización: Antes del ciclo, se inicializaron l con 0 y r con n - 1, el arreglo completo. Por lo que se cumple que si el elemento target está en el arreglo, está entre l y r. Se cumple la invariante.\\
    Mantenimiento: Supongamos que se cumple la invariante antes de la i-ésima iteración. Por lo que el target se encuentra entre l y r.
    Al ejecutar el algoritmo de nuevo, se divide el arreglo entre tres.
    Si alguno de los dos pivotes quedó sobre el target, regresamos el índice de este. En este caso, se cumple la invariante porque como ya terminó el algoritmo, no hay i+1-ésima iteración.
    Si el target es menor que el elemento en el primer pivote,
    simplemente movemos r una posición menos que micha1. El target es menor o igual al elemento de r. Y mayor o igual a l por la invariante.
    Si target es mayor al segundo pivote, movemos l una posición más que micha2. En este caso, es mayor o igual a l. Y menor o igual a r por la invariante.
    En otro caso, se mueve a l una posición más que micha1 y a r una posición menos que micha2. Como no se cumplieron los casos anteriores y por la invariante, se tiene que target estaría entre l y r.
    Por lo tanto, se mantiene la invariante.\\
    Finalización: El ciclo termina por los casos descrito allá arriba o si el elemento no está en el arreglo. En este caso, se va reduciendo el intervalo hasta que solamente queda el arreglo vacío para buscar, lo que, según nuestra invariante, indica que el target no se encuentra en el arreglo, entonces se retorna -1. Y el algoritmo es correcto.

    \item[2.B] Diseña un algoritmo recursivo que generalice para proponer una búsqueda $k-$enaria que divida el problema en $k-$partes; se deben hacer a lo más $k - 1$ comparaciones y trabajar con un problema de tamaño $n/k$. ¿Cómo cambiaría el análisis de complejidad en tiempo?\\
    \begin{algorithm}[H]
    \caption{kenaria}
    \KwIn{Arreglo ordenado $A$ de longitud $n$, $target$, l, r}
    \KwOut{Índice del elemento si se encuentra, $-1$ en otro caso}
    \SetAlgoLined
    \Begin{
    pivote1 $\gets l + \frac{(r - l)}{k}$\\
    pivote2 $\gets l + 2\frac{(r - l)}{k}$\\
    \vdots
    pivotei $\gets l + i\frac{(r - l)}{k}$\\
    pivotei+1 $\gets r - (i + 1)\frac{(r - l)}{k}$\\
    \vdots
    pivotek-2 $\gets r - 2\frac{r -l}{k}$\\
    pivotek-1 $\gets r - \frac{r -l}{k}$\\
    \If{A[pivote1] = target}{ \Return{pivote1} }
    \vdots
    \If{A[pivotei] = target}{ \Return{$pivote_i$} }
    \vdots
    \If{A[pivotek-1] = target}{ \Return{pivotek-1} }
    \ElseIf{target $<$ A[pivote1]}{ \Return{kenaria(A, target, l, $pivote_1$ - 1)} }
    \vdots
    \ElseIf{A[pivotei] $<$ target $<$ A[$pivote_{i+1}$]}{ \Return{kenaria(A, target, $pivote_i$ + 1, $pivote_{i+1}$ - 1)} }
    \vdots
    \Else{kenaria(A, target, $pivote_{k-1}$ + 1, r)} \Return{$-1$} } \end{algorithm}
Este algoritmo, al dividir el arreglo en k partes con k-1 pivotes, sería $O(log_kn)$, a pesar de que aumentan el número de operaciones por ciclo, se reduce el número de llamadas recursivas entre más grande sea k. Son del orden $O(log_k{n})$. Y por cada llamada recursiva, se harían O(1) operaciones. Por lo que el análisis de complejidad sería similar. Cada llamada recursiva opera sobre $1/k$ la longitud longitud del arreglo que se trabajó en la llamada anteror.
\end{itemize}

% P-3
\section*{Ejercicio 3}
Un polinomio $p(x)$ de grado $n$ es una ecuación de la forma:
\[
    p(x)=\sum_{i=0}^n a_ix^j
\]
donde $x$ es un número real y $a_i \in \mathbb{R}$ son constantes.
\begin{itemize}
    \item[3.a] Describe un algoritmo simple de complejidad $O(n^2)$ para evaluar $p(x)$, considerando que $x$ es un valor de entrada.\\
    La forma simple de evaluar un polinomio de grado $n$ es calcular cada término de la suma por separado y después sumarlos, lo que nos lleva a trabajar con dos \textbf{for} anidados, en el primero se hacen \textit{n} iteraciones y para el \textbf{for} interno calculamos $x^i$ multiplicamos $x$ por si mismo $i$ veces, para después en el \textbf{for} exterior multiplicamos por $a_i$ y lo sumamos a lo que ya teniamos.\\
    En cada iteración del primer \textbf{for} el \textbf{for} interno hace \textit{i} iteraciones, lo que nos ayuda a saber el número de operaciones que hace para poder sacar la complejidad que es $0+1+2+\dots+n = \frac{n(n+1)}{2} = O(n^2)$, y lo que queda son una multiplicación, una suma y una asignación lo que tiene complejidad constante, por lo tanto el algoritmo tiene complejidad $O(n^2)$.\\
    El algoritmo es el siguiente, recibe un arreglo $A$ con $a_i \in \mathbb{R}$ constantes y un número real $x$ y devuelve el resultado de $p(x)$.\\
    \RestyleAlgo{ruled}
    \LinesNumbered
    \renewcommand{\algorithmcfname}{Algoritmo}
    \begin{algorithm}[H]
        \caption{Evaluación de un polinomio $p(x)$ de grado $n$}
        $potencia \gets 1$\\
        $longitud \gets len(A)$\\
        $resultado \gets 0$\\
        \For{$i \gets 0$ \KwTo $longitud$}{
            \For{$j \gets 1$ \KwTo $i$}{
                $potencia \gets potencia \cdot x$\\
            }
            $resultado \gets resultado + A[i] \cdot potencia$\\
        }
        \Return $resultado$
    \end{algorithm}
    \item[3.b] Considera la siguiente expresión (método de Horner) para reescribir $p(x)$:
    \[
        p(x) = a_0 + x(a_1 + x(a_2 + x(a_3 + . . . + x(a_{n-1} + xa_n). . .)))
    \]
    ¿Cuál es el número de sumas y multiplicaciones que se realizan en este método?\\
    Este método se evalúa primero lo más adentro primero y después lo que este por fuera, entonces, empezando con $a_n$ que se multiplica por $x$ y se suma a $a_{n-1}$ entonces ya llevamos 1 multiplicación y una suma, pero eso que teniamos lo vamos a multiplicar otra vez por $x$ y eso se le suma a $a_{n-2}$ lo que da dos sumas y dos multiplicaciones, pero de nuevo eso se multiplica por $x$ y se le suma a $a_{n-3}$ y así hasta llegar a que se multiplique por $x$ y se sume a $a_0$ y como ya no hay más constantes $a_i$ anteriores a este entonces ya no hay más multiplicaciones ni sumas que hacer por lo cual se hizo una multiplicación y  una suma por cada $a_i$.\\
    Por lo tanto, en este método se realizan $n$ sumas y $n$ multiplicaciones.
    \item[3.c] Propón un algoritmo recursivo para el método anterior.\\
    Para el algoritmo recursivo, tomaremos como caso base si la longitud del arreglo es $0$ entonces regresara $0$ pero si no es $0$ tomaremos el primer elemento del arreglo y se lo sumaremos a $x$ multiplicado por la misma función con el resto del arreglo sin el primer elemento y $x$ como argumentos.\\
    El algoritmo se llamara \texttt{horner\_Recursivo(A, x)} donde $A$ es el arreglo con los coeficientes del polinomio y $x$ es el valor en el que se evaluara el polinomio.\\
    \begin{algorithm}[H]
        \caption{Algoritmo recursivo para el método de Horner}
        $longitud \gets len(A)$\\
        $resto \gets A[1:]$\\
        \If{$longitud == 0$}{
            \Return $0$
        }
        \Return $A[0] + x \cdot horner\_Recursivo(resto, x)$
    \end{algorithm}
    ¿La complejidad asintótica es diferente al análisis anterior?\\
    La complejidad asintótica no es diferente al análisis anterior ya que en este método recursivo se realiza una suma y una multiplicación por cada elemento del arreglo, es decir, como toma solo el primer elemento y luego lo suma a $x$ multiplicado por la función menos ese elemento lo hara $n$ veces, por lo tanto la complejidad asintótica es $O(n)$.\\
    ¿Cambiaría la complejidad (en tiempo o espacio) si se propusiera el método en su versión iterativa?\\
    Veamos como sería el algoritmo iterativo, en este primero declaramos a $p(x)$ con el último elemento del arreglo y después empezamos desde el indice del penúltimo elemento y le sumamos a $p(x)$ el elemento en ese indice más $x$ por $p(x)$:\\
    \begin{algorithm}[H]
        \caption{Algoritmo iterativo}
        $long \gets len(A)$\\
        $resultado \gets A[long - 1]$\\
        \For{$i \gets long - 2$; $i\geq 0$; $i--$}{
            $resultado \gets A[i] + x \cdot resultado$
        }
        \Return $resultado$
    \end{algorithm}
    Por lo tanto ya con el algoritmo iterativo, veamos la complejidad en tiempo, tanto en el iterativo como en el recursivo solamente se hacen $n$ sumas y $n$ multiplicaciónes por lo que la complejidad en tiempo del algoritmo recursivo y del algoritmo iterativo es de $O(n)$.\\
    Para la complejidad en espacio, si consideramos que en el algoritmo recursivo se asigna memoria en cada llamada de la función entonces este tiene complejidad $O(n)$ en espacio, mientras que el algoritmo iterativo solo hace dos declaraciones considerando que el arreglo viene en la entrada, por lo tanto, el algoritmo iterativo tiene complejidad $O(1)$ en espacio, por lo cual si podemos ver la diferencia entre estas dos opciones.
\end{itemize}

% P-4
\section*{Ejercicio 4}
Considera el siguiente algoritmo:
\begin{algorithm}
    \While{$a > 0$}{
        \If{$a < b$}{
            $(a, b) \gets (2a, b - a)$
        }
        \Else{$(a, b) \gets (a-b, 2b)$}
    }
\end{algorithm}
\begin{itemize}
    \item ¿Qué hace el algoritmo?\\
    El algoritmo solo cambia los valores que tienen $a$ y $b$, en dado caso de que el algoritmo termine el valor final de $a$ sera $0$ y el valor final de $b$ sera la suma de los valores originales de $a$ y $b$. Pero si el algoritmo no termina, es decir, en ningún momento $a = 0$, entonces, se cicla y permanece cambiando los valores de $a$ y $b$, con la excepción de si $b = 0$ por que entonces se cicla pero no cambia nunca el valor de ninguno de los dos.
    \item Asume como precondición que $a, b > 0$.\\
    ¿Para qué valores de $a, b$ se puede garantizar que el algoritmo termina?\\
    El algoritmo termina siempre y cuando en algún punto $a = b$, es decir, cualquier valor que tome $a$ tiene  que ser el mismo valor para $b$ para que entonces el algoritmo pueda terminar al inicio, pero esto tambien puede suceder en alguna iteración, si en algún momento el valor que tenga $a$ multiplicado por 2 es lo mismo que si a $b$ le restamos el valor de $a$ antes de multiplicarlo o viceversa, cambiando $a$ por $b$ y $b$ por $a$, además una forma de que termine es si los valores iniciales de $a$ y $b$ sumados dan como resultado una potencia de dos.
    \item Si el algoritmo termina, ¿en cuántos pasos lo hace?\\
    Si el algoritmo no termina, justifica la respuesta.\\
    Si el algoritmo termina depende de sus entradas para saber en cuantos pasos lo hara si sus entradas son iguales entonces terminara en un solo paso, si sus entradas son diferentes pero en un inicio da la opción de que el mayor menos el menor de lo mismo que el menor multiplicado por 2 entonces terminara en un solo paso, pero si la suma de las entradas da como resultado una potencia de 2 entonces el número de pasos en los que terminara sera menor o igual al $\log_2(S)$ siendo \textit{S} la suma de las entradas.\\
    En cambio, si el algoritmo no termina será por que $a$ nunca sera igual a $0$, entonces $a$ se estara multiplicando por 2 o variando su valor pero como sigue siendo mayor que 0, entonces el While nunca va a terminar y el algoritmo se va a ciclar.
\end{itemize}

% P-5
\section*{Ejercicio 5}
En clase revisamos la notación asintótica $O-$grande, $\Omega$ y $\Theta$. Algunos autores utilizan también la notación $o$ ($o-$ pequeña) para resaltar que $f$ no solo está acotada por $g$, sino que crece estrictamente más lento. Formalmente:
\[
    o-\text{pequeña: Una función } f(n) \text{ es } o(g(n)) \text{ si } \forall b \in \mathbb{R}, \, b>0 \,\, \exists a \in \mathbb{Z},\, a>0
\]
\[
    \text{tal que } \forall n \geq a, \, f(n) < b \cdot g(n)
\]
Informalmente, podemos pensar en $O-$grande como una comparación $\leq$ entre funciones, y $o-$pequeña como una comparación $<$; es decir, no importa qué tan pequeña elegimos a b, $f(n)$ será más pequeña que $bg(n)$ a partir de cierta $n$.
\begin{itemize}
    \item[5.a] Prueba que:
        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \begin{itemize}
            \item $n$ no es $o(2n)$ pero $n$ es $o(n^2)$\\
            \textbf{Demostración:}\\
            $\bullet$ Empecemos por demostrar que \textbf{$n$ no es $o(2n)$}.\\
            Para ello, debemos mostrar que existe al menos un $b > 0$ tal que para cualquier $a > 0$ existe una $n \geq a$ tal que $n \geq b \cdot 2n$ (contraejemplo).\\
            Tomemos $b = \frac{1}{2}$. Entonces, para cualquier $a > 0$ podemos tomar $n = 1$. Así, tenemos que:
            \[
            1 < \frac{1}{2} \cdot 2(1)
            \]
            \[
            \Rightarrow 1 < 1
            \]
            Lo cual es un contraejemplo a la definición de $o-$pequeña.\\
            Por lo tanto, $n$ no es $o(2n)$.\\
            $\bullet$ Ahora, demostraremos que \textbf{$n$ es $o(n^2)$}.\\
            Procedemos a mostrar que para cualquier $b > 0$ existe un $a > 0$ tal que para cualquier $n \geq a$ se cumple que:
            \[
            n < b \cdot n^2
            \]
            Vemos que podemos dividir ambos lados entre $n$ (ya que por definición $n > 0$), obteniendo:
            \[
            1 < b \cdot n
            \]
            Procedemos a despejar $n$:
            \[
            \Rightarrow \frac{1}{b} < n
            \]
            Ahora podríamos decir que $a = \frac{1}{b}$ pero tenemos el detalle de que $a$ debe ser un entero positivo por la definición, por lo que tomamos $a = \lfloor \frac{1}{b} \rfloor + 1$, que es un entero positivo.\\
            Por lo tanto, hemos demostrado que $n$ es $o(n^2)$. \\
            \qed


            \item $log_{10}(n)$ es $O(log_2(n))$ pero no es $o(log_2(n))$\\
            \textbf{Demostración:}\\
            $\bullet$ Realizamos el mismo procedimiento que en el inciso anterior.\\
            Primero, demostraremos que \textbf{$log_{10}(n)$ es $O(log_2(n))$}.\\
            Procedemos a mostrar que existe una constante $c \in \mathbb{R^{+}}$ y un $n_0 \in \mathbb{N}$ tales que $\forall n \geq n_0$ se cumple que:
            \[
            log_{10}(n) \leq c \cdot log_2(n)
            \]
            Aqui podemos hacer uso de la propiedad de los logaritmos que dice que:
            \[
            log_a(b) = \frac{log_c(b)}{log_c(a)}
            \]
            Por lo que podemos reescribir $log_{10}(n)$ como:
            \[
            log_{10}(n) = \frac{log_2(n)}{log_2(10)}
            \]
            Esto lo usamos a conveniencia, pues ahora podemos sustituir en la desigualdad:
            \[
            \frac{log_2(n)}{log_2(10)} \leq c \cdot log_2(n)
            \]
            Ahora podemos dividir ambos lados entre $log_2(n)$, para esto debemos tener en cuenta en que $log_2(n) > 0$, por lo que tomamos $n_0 = 2$ (pues si $n_0 = 1$ tenemos $log_2(1) = 0$). Entonces, tenemos:
            \[
            \frac{1}{log_2(10)} \leq c
            \]
            Por lo que podemos tomar $c = \frac{1}{log_2(10)}$.\\
            Por tanto, hemos demostrado que $log_{10}(n)$ es $O(log_2(n))$.\\
            Con $n_0 = 2$ y $c = \frac{1}{log_2(10)}$ $\forall n \geq 2$.\\


            $\bullet$ Ahora demostremos que \textbf{$log_{10}(n)$ no es $o(log_2(n))$}.\\
            Por lo que exhibiremos un contraejemplo, un $b > 0$ tal que para cualquier $a > 0$ existe una $n \geq a$ tal que no se cumpla la desigualdad
            \[
            log_{10}(n) < b \cdot log_2(n)
            \]
            Podemos hacer la sustitucion que hicimos anteriormente y reescribir la desigualdad como:
            \[
            \frac{log_2(n)}{log_2(10)} < b \cdot log_2(n)
            \]
            Dividiendo ambos lados entre $log_2(n)$ (con $n \geq 2$) obtenemos:
            \[
            \frac{1}{log_2(10)} < b
            \]
            Podemos hacer el calculo de $\frac{1}{log_2(10)} \approx 0.3010$, quedando la desigualdad como:
            \[
            0.3010 < b
            \]
            Pero ahora podemos tomar por conveniencia a $b = 0.1$, que es un valor menor a $0.3010$, lo cual es lo que buscabamos en un inicio pues hemos encontrado un $b$ que no cumple la desigualdad (contraejemplo).\\
            Por lo tanto, hemos demostrado que $log_{10}(n)$ no es $o(log_2(n))$.\\
            \qed




            \item si $x, y > 1$, $log_x(n)$ es $o(n^y)$\\
            \textbf{Demostración:}\\
            Procedemos a demostrar lo que se nos pide mediante la definición de $o-$pequeña.\\
            Debemos mostrar que para cualquier $b > 0$ existe un $a > 0$ tal que para cualquier $n \geq a$ se cumple que:
            \[
            log_x(n) < b \cdot n^y
            \]
            Nuevamente, notemos que podemos hacer uso de la propiedad de los logaritmos sobre el cambio de base, por lo que podemos reescribir $log_x(n)$ como:
            \[
            log_x(n) = \frac{log_2(n)}{log_2(x)}
            \]
            Y observemos que $log_2(x)$ es una constante positiva pues $x > 1$.\\
            Sustituyendo en la desigualdad, tenemos que:
            \[
            \frac{log_2(n)}{log_2(x)} < b \cdot n^y
            \]
            O bien, multiplicando ambos lados por $log_2(x)$ (que es positivo, por lo que no cambia la desigualdad):
            \[
            \Rightarrow \frac{log_2(n)}{log_2(x)} \cdot log_2(x) < b \cdot n^y \cdot log_2(x)
            \]
            \[
            \Rightarrow log_2(n) < b \cdot n^y \cdot log_2(x)
            \]
            Ahora nosotros buscamos que logaritmo crezca más lento que una función polinómica para que $log_x(n)$ sea $o(n^y)$, y sabemos que $b$ y $log_2(x)$ son constantes positivas, por tanto solo nos bastaría demostrar que:
            \[
            log_2(n) < n^y
            \]
            Sabemos que el logaritmo crece más lento que cualquier función polinómica, pero lo mostraremos formalmente con uso de los límites.\\
            Consideremos el siguiente límite:
            \[
            \lim_{n \to \infty} \frac{log_2(n)}{n^y}
            \]

            Aplicando la regla de L'Hôpital, tenemos que:
            \[
            \lim_{n \to \infty} \frac{log_2(n)}
            {n^y} \xrightarrow[\text{L'Hôpital}]{} \lim_{n \to \infty} \frac{\frac{1}{n \cdot ln(2)}}{y \cdot n^{y-1}} = \lim_{n \to \infty} \frac{1}{y \cdot ln(2) \cdot n^y} = 0
            \]
            Y como vemos el límite tiende a 0, entonces:
            \[
            log_2(n) < n^y
            \]
            Por lo que el límite tiende a 0, es decir, $log_2(n)$ crece más lento que $n^y$.\\
            Por lo tanto, $log_x(n)$ es $o(n^y)$.\\
            \qed



        \end{itemize}
    \item[5.b] ¿Qué pasa si cambiamos la función $f(n) < b \cdot g(n)$ por $f(n) \leq b \cdot g(n)$?, ¿Cambiaría el significado de $o-$ pequeña?
    \textbf{Respuesta:}\\
    Cambiaria la definición formal de $o-$pequeña, aunque la diferencia entre $<$ y $\leq$ pudiera ser mínima, puesto que en ambos casos $f(n)$ debería seguir estando estrictamente acotada por $g(n)$, pero en términos generales, $o-$pequeña \textbf{seguiria significando lo mismo}, es decir, que $f(n)$ crece estrictamente más lento que $g(n)$ solo que ahora $f(n)$ podría llegar a ser igual a $b \cdot g(n)$ en algún punto a partir de una $n$ suficientemente grande, y aun asi cumpliría que $b > 0$ tal y como indica la definición.\\

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{itemize}

% P-6
\section*{Ejercicio 6}
Considera las siguientes recurrencias. En cada caso, demuestra la forma cerrada de $T(n)$ por inducción.
\begin{itemize}
    \item[6.a]
    \[
        T(n) = \left\{ \begin{array}{ll}
        1 & \text{si } n=1\\ T(n-1)+n & \text{en otro caso} \end{array}\right.
    \]
    \[
        T(n) = n(n+1)/2
    \]
    \\\textbf{Demostración:}\\
    Primero procedemos a obtener la forma cerrada de $T(n)$ mediante la expansión de la recurrencia:
    \[
        T(n) = T(n-1) + n
    \]
    \[
        = T(n-2) + (n-1) + n
    \]
    \[
        = T(n-3) + (n-2) + (n-1) + n
    \]
    \[
        ...
    \]
    \[
        = T(1) + 2 + 3 + ... + (n-2) + (n-1) + n
    \]
    \[
    \Rightarrow T(n) = 1 + 2 + 3 + ... + (n-2) + (n-1) + n
    \]
    Vemos que se trata sobre la suma de los primeros $n$ enteros positivos:
    \[
    \Rightarrow T(n) = \frac{n(n+1)}{2}
    \]
    Como vemos, la forma cerrada de $T(n)$ es $\frac{n(n+1)}{2}$.\\
    Ahora procedemos a demostrar por \textbf{inducción} que la forma cerrada es correcta.\\
    \textbf{Caso Base:} Tomamos a $n = 1$ y ver si se cumple:
    \[
        T(1) = 1
    \]
    \[
        \frac{1(1+1)}{2} = 1
    \]
    \[
        1 = 1
    \]
    Por lo tanto, el caso base se cumple.\\
    \textbf{Hipotesis de Inducción:} Supongamos que para alguna $k \geq 1$ se cumple que:
    \[
        T(k) = \frac{k(k+1)}{2}
    \]
    \textbf{Paso Inductivo:} Demostraremos que se cumple para $k + 1$:\\
    Queremos demostrar o llegar que:
    \[
        T(k+1) = \frac{(k+1)(k+2)}{2}
    \]
    Por la definición de la recurrencia, tenemos que:
    \[
        T(k+1) = T(k) + (k + 1)
    \]
    Por hipotesis de inducción, sabemos que $T(k) = \frac{k(k+1)}{2}$, por lo que sustituimos:
    \[
        T(k+1) = \frac{k(k+1)}{2} + (k + 1)
    \]
    \[
        \Rightarrow = \frac{k(k+1)+2(k + 1)}{2}
    \]
    Desarrollamos el numerador:
    \[
        \Rightarrow = \frac{k^2 + 3k + 2}{2}
    \]
    Factorizamos el numerador:
    \[
        \Rightarrow = \frac{(k+1)(k+2)}{2}
    \]
    Y como vemos, hemos llegado a lo que queríamos demostrar.\\
    Por lo tanto, hemos demostrado que la forma cerrada de $T(n)$ es correcta, mediante inducción.\\
    \qed


    \item[6.b]
    \[
        T(n) = \left\{ \begin{array}{ll}
        1 & \text{si } n=0\\ T(n-1)+2^n & \text{en otro caso} \end{array}\right.
    \]
    \\
    \[
        T(n) = 2^{n+1}-1
    \]
    \\\textbf{Demostración:}\\
    Realizamos el mismo procedimiento que en el inciso anterior.\\
    Obtenemos su forma cerrada mediante la expansión de la recurrencia:
    \[
        T(n) = T(n-1) + 2^n
    \]
    \[
        = T(n-2) + 2^{n-1} + 2^n
    \]
    \[
        = T(n-3) + 2^{n-2} + 2^{n-1} + 2^n
    \]
    \[
        ...
    \]
    \[
        = T(0) + 2^1 + 2^2 + ... + 2^{n-1} + 2^n
    \]
    \[
    \Rightarrow T(n) = 1 + 2^1 + 2^2 + ... + 2^{n-1} + 2^n
    \]
    Vemos que se trata sobre la suma de una serie geométrica:
    \[
    \Rightarrow T(n) = 2^{n+1} - 1
    \]

    Ahora procedemos a demostrar por \textbf{inducción} que la forma cerrada obtenida es correcta.\\
    \textbf{Caso Base:} Tomamos a $n = 0$ y ver si se cumple:
    \[
        T(0) = 1
    \]
    \[
        2^{0+1} - 1 = 1
    \]
    \[
        1 = 1
    \]
    Por lo tanto, el caso base se cumple.\\
    \textbf{Hipotesis de Inducción:} Supongamos que para alguna $k \geq 0$ se cumple que:
    \[
        T(k) = 2^{k+1} - 1
    \]
    \textbf{Paso Inductivo:} Demostraremos que se cumple para $k + 1$:\\
    Queremos demostrar o llegar que:
    \[
        T(k+1) = 2^{(k+2)} - 1
    \]
    Por la definición de la recurrencia, tenemos que:
    \[
        T(k+1) = T(k) + 2^{k + 1}
    \]
    Podemos hacer uso de la hipotesis de inducción, por lo que sustituimos:
    \[
    \Rightarrow = 2^{k+1} - 1 +
        2^{k + 1}
    \]
    \[        \Rightarrow = 2 \cdot 2^{k+1} - 1
    \]
    \[        \Rightarrow = 2^{(k+1)+1} - 1
    \]
    \[        \Rightarrow = 2^{k+2} - 1
    \]
    Y como vemos, hemos llegado a lo que queríamos demostrar.\\
    Por lo tanto, hemos demostrado que la forma cerrada de $T(n)$ es correcta, mediante inducción.\\
    \qed


    \item[6.c]
    \[
        T(n) = \left\{ \begin{array}{ll}
        1 & \text{si } n=0\\ 2T(n-1) & \text{en otro caso} \end{array}\right.
    \]
    \\
    \[
        T(n) = 2^n
    \]
    Procedemos encontrar su forma cerrada mediante la expansión de la recurrencia que se nos da:
    \[
        T(n) = 2T(n-1)
    \]
    \[
        = 2(2T(n-2)) = 2^2T(n-  2)
    \]
    \[
        = 2^2(2T(n-3)) = 2^3T(n-3)
    \]
    \[        ...
    \]
    \[        = 2^{n-1}T(1)
    \]
    \[    \Rightarrow T(n) = 2^{n-1}(2T(0))
    \]
    \[    \Rightarrow T(n) = 2^{n-1}(2(1))
    \]
    Vemos que $T(0) = 1$ por la definición de la recurrencia.\\
    \[    \Rightarrow T(n) = 2^n
    \]
    Una vez que deducimos la forma cerrada de $T(n)$, procedemos a demostrar por \textbf{inducción} que la forma cerrada es correcta.\\
    \textbf{Caso Base:} Tomamos a $n = 0$:
    \[
        T(0) = 1
    \]
    \[        2^0 = 1
    \]
    \[        1 = 1
    \]
    Por lo tanto, el caso base se cumple.\\
    \textbf{Hipotesis de Inducción:} Supongamos que para alguna $k \geq 0$ se cumple que:
    \[        T(k) = 2^k
    \]
    \textbf{Paso Inductivo:} Demostraremos que se cumple para $k + 1$:\\
    Queremos demostrar o llegar que:
    \[        T(k+1) = 2^{k+1}
    \]
    Por la definición de la recurrencia, tenemos que:
    \[        T(k+1) = 2T(k)
    \]
    Aplicamos la hipotesis de inducción, por lo que sustituimos:
    \[    \Rightarrow = 2(2^k)
    \]
    \[        \Rightarrow = 2^{k+1}
    \]
    Y como vemos, hemos llegado a lo que queríamos demostrar.\\
    Por lo tanto, hemos demostrado que la forma cerrada de $T(n)$ es correcta.\\
    \qed


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{itemize}

\end{document}
